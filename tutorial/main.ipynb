{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acfbdc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pyabc import Distribution, RV\n",
    "from sbi.utils import BoxUniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11544679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.configdefaults): g++ not available, if using conda: `conda install gxx`\n",
      "WARNING (pytensor.configdefaults): g++ not detected!  PyTensor will be unable to compile C-implementations and will default to Python. Performance may be severely degraded. To remove this warning, set PyTensor flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "from src.utils import set_seed\n",
    "from src.inference import SBIEngine\n",
    "from models.epidemic_models import simulate_seir  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfef804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#] Seed has been fixed to: 0\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. Global Setup\n",
    "set_seed(0) # Fix seed for reproducibility\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a441e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define Priors (Two versions for pyabc and sbi compatibility)\n",
    "# pyabc version (loc, scale) -> [0.2, 1.5], [0.1, 0.5], [0.05, 0.40]\n",
    "pyabc_prior = Distribution(\n",
    "    beta=RV(\"uniform\", 0.2, 1.3),\n",
    "    kappa=RV(\"uniform\", 0.1, 0.4),\n",
    "    gamma=RV(\"uniform\", 0.05, 0.35)\n",
    ")\n",
    "\n",
    "# sbi version (low, high)\n",
    "sbi_prior = BoxUniform(\n",
    "    low=torch.tensor([0.2, 0.1, 0.05]),\n",
    "    high=torch.tensor([1.5, 0.5, 0.40])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52c9aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Simulator Wrappers\n",
    "def simulator(params):\n",
    "    p = [params['beta'], params['kappa'], params['gamma']]\n",
    "    output = simulate_seir(p, [99990, 0, 10, 0], duration=100)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37f8ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(num_sims=10000):\n",
    "    \"\"\"Generates training dataset for standard NPE and NPE-LSTM\"\"\"\n",
    "    print(f\"[*] Generating {num_sims} simulations for NPE training...\")\n",
    "    thetas = sbi_prior.sample((num_sims,))\n",
    "    xs = []\n",
    "    for t in thetas:\n",
    "        data = simulate_seir(t.numpy(), [99990, 0, 10, 0], duration=100)\n",
    "        xs.append(torch.tensor(data, dtype=torch.float32))\n",
    "    return thetas, torch.stack(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c372ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prepare Observed Data (Ground Truth)\n",
    "true_params = [0.8, 0.3, 0.1]\n",
    "observed_raw = simulate_seir(true_params, [99990, 0, 10, 0], duration=100)\n",
    "obs_dict = {\"data\": observed_raw}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "489360c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = SBIEngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7fc25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Running SMC-ABC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABC.History INFO: Start <ABCSMC id=1, start_time=2026-02-03 16:22:21>\n",
      "ABC INFO: Calibration sample t = -1.\n",
      "ABC INFO: t: 0, eps: 1.35598722e+04.\n",
      "ABC INFO: Accepted: 100 / 357 = 2.8011e-01, ESS: 1.0000e+02.\n",
      "ABC INFO: t: 1, eps: 3.55534378e+03.\n",
      "ABC INFO: Accepted: 100 / 530 = 1.8868e-01, ESS: 7.6360e+01.\n",
      "ABC INFO: t: 2, eps: 1.59044881e+03.\n",
      "ABC INFO: Accepted: 100 / 684 = 1.4620e-01, ESS: 4.5645e+01.\n",
      "ABC INFO: Stop: Total simulations budget.\n",
      "ABC.History INFO: Done <ABCSMC id=1, duration=0:00:03.915766, end_time=2026-02-03 16:22:25>\n"
     ]
    }
   ],
   "source": [
    "abc_samples = engine.run_abc(\n",
    "    obs_data=obs_dict,\n",
    "    prior=pyabc_prior,\n",
    "    simulator_func=simulator,\n",
    "    num_simulations=1000, \n",
    "    population_size=100,\n",
    "    num_samples=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5711492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>kappa</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.783400</td>\n",
       "      <td>0.117561</td>\n",
       "      <td>0.353310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.675679</td>\n",
       "      <td>0.108252</td>\n",
       "      <td>0.471968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.755180</td>\n",
       "      <td>0.160098</td>\n",
       "      <td>0.418195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.629427</td>\n",
       "      <td>0.047169</td>\n",
       "      <td>0.396211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.638646</td>\n",
       "      <td>0.114563</td>\n",
       "      <td>0.500797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.805238</td>\n",
       "      <td>0.126041</td>\n",
       "      <td>0.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.879711</td>\n",
       "      <td>0.182636</td>\n",
       "      <td>0.356947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.557212</td>\n",
       "      <td>0.088804</td>\n",
       "      <td>0.510447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.765968</td>\n",
       "      <td>0.222924</td>\n",
       "      <td>0.501232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0.960995</td>\n",
       "      <td>0.209204</td>\n",
       "      <td>0.343395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name      beta     gamma     kappa\n",
       "id                                \n",
       "298   0.783400  0.117561  0.353310\n",
       "261   0.675679  0.108252  0.471968\n",
       "250   0.755180  0.160098  0.418195\n",
       "204   0.629427  0.047169  0.396211\n",
       "292   0.638646  0.114563  0.500797\n",
       "..         ...       ...       ...\n",
       "205   0.805238  0.126041  0.321500\n",
       "239   0.879711  0.182636  0.356947\n",
       "204   0.557212  0.088804  0.510447\n",
       "236   0.765968  0.222924  0.501232\n",
       "213   0.960995  0.209204  0.343395\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e060393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABC.History INFO: Start <ABCSMC id=1, start_time=2026-02-03 16:22:40>\n",
      "ABC INFO: Calibration sample t = -1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] PNPE Stage 1: ABC Preconditioning...\n",
      "[*] Running SMC-ABC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABC INFO: t: 0, eps: 1.51894131e+04.\n",
      "ABC INFO: Accepted: 100 / 302 = 3.3113e-01, ESS: 1.0000e+02.\n",
      "ABC INFO: t: 1, eps: 3.35711937e+03.\n",
      "ABC INFO: Accepted: 100 / 420 = 2.3810e-01, ESS: 7.5285e+01.\n",
      "ABC INFO: Stop: Total simulations budget.\n",
      "ABC.History INFO: Done <ABCSMC id=1, duration=0:00:01.881776, end_time=2026-02-03 16:22:42>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] PNPE Stage 2: Training NPE with preconditioned samples...\n",
      "[*] Running NPE (use_lstm=True) with batch size 64...\n",
      " Neural network successfully converged after 98 epochs.\n",
      "        -------------------------\n",
      "        ||||| ROUND 1 STATS |||||:\n",
      "        -------------------------\n",
      "        Epochs trained: 98\n",
      "        Best validation performance: -4.5658\n",
      "        -------------------------\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11610it [00:00, 79323.06it/s]            \n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# METHOD 4: PNPE (Preconditioned NPE)\n",
    "# ==========================================================\n",
    "# PNPE Stage 1 uses ABC, then Stage 2 trains a refined NPE\n",
    "pnpe_post, pnpe_samples = engine.run_pnpe(\n",
    "    obs_data=observed_raw,\n",
    "    pyabc_prior=pyabc_prior,\n",
    "    sbi_prior=sbi_prior,\n",
    "    simulator_func=simulator,\n",
    "    num_simulations=1000,\n",
    "    num_samples=10000, \n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# METHOD 2: Standard NPE (No LSTM embedding)\n",
    "# ==========================================================\n",
    "npe_post, npe_samples = engine.run_npe(\n",
    "    obs_data=observed_raw,\n",
    "    prior=sbi_prior,\n",
    "    thetas=thetas_train,\n",
    "    xs=xs_train,\n",
    "    use_lstm=False,\n",
    "    num_samples=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d522099d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thetas_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ==========================================================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# METHOD 2: Standard NPE (No LSTM embedding)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ==========================================================\u001b[39;00m\n\u001b[32m      4\u001b[39m npe_post, npe_samples = engine.run_npe(\n\u001b[32m      5\u001b[39m     obs_data=observed_raw,\n\u001b[32m      6\u001b[39m     prior=sbi_prior,\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     thetas=\u001b[43mthetas_train\u001b[49m,\n\u001b[32m      8\u001b[39m     xs=xs_train,\n\u001b[32m      9\u001b[39m     use_lstm=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     10\u001b[39m     num_samples=\u001b[32m10000\u001b[39m\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'thetas_train' is not defined"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# METHOD 2: Standard NPE (No LSTM embedding)\n",
    "# ==========================================================\n",
    "npe_post, npe_samples = engine.run_npe(\n",
    "    obs_data=observed_raw,\n",
    "    prior=sbi_prior,\n",
    "    thetas=thetas_train,\n",
    "    xs=xs_train,\n",
    "    use_lstm=False,\n",
    "    num_samples=10000\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
