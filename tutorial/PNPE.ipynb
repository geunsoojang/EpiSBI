{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c126ab-618f-4062-ba22-7e5135eb22c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "_ = np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc01ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_system(y, t, beta, kappa, gamma, N):\n",
    "    S, E, I, R = y\n",
    "    dSdt = -beta * S * I / N\n",
    "    dEdt = beta * S * I / N - kappa * E\n",
    "    dIdt = kappa * E - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return [dSdt, dEdt, dIdt, dRdt]\n",
    "\n",
    "def simulate(parameters, ic, T):\n",
    "    beta, kappa, gamma = parameters\n",
    "    S0, E0, I0, R0 = ic\n",
    "\n",
    "    N = S0 + E0 + I0 + R0\n",
    "    y0=ic\n",
    "    \n",
    "    t = np.arange(T+1)\n",
    "    ret = odeint(ode_system, y0, t, args=(beta, kappa, gamma, N))\n",
    "\n",
    "    return kappa * ret[1:,1]\n",
    "\n",
    "def poisson_noise(simulation):\n",
    "    \n",
    "    with_noise = np.random.poisson(np.maximum(simulation, 1e-6))\n",
    "\n",
    "    return np.asarray(with_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d3faa1-2a3c-448a-bc13-2a0030a038a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N  = 100000\n",
    "E0 = 0\n",
    "I0 = 10\n",
    "R0 = 0\n",
    "S0 = N - E0 - I0 - R0\n",
    "\n",
    "init_cond = [S0, E0, I0, R0]\n",
    "\n",
    "duration=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51e5684b-bfcc-4494-ae59-d2ba2a004207",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../sim_dataset.pkl', 'rb') as f:\n",
    "    simulation_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eab87bd-7e04-482a-8936-dcd15ad875b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(params):\n",
    "    pvec = [\n",
    "        params['beta'],\n",
    "        params['kappa'],\n",
    "        params['gamma']\n",
    "    ]\n",
    "    sim = simulate(pvec, init_cond, T=duration)\n",
    "    \n",
    "    return {'cases1': poisson_noise(sim)}\n",
    "\n",
    "def distance(sim, obs):\n",
    "\n",
    "    return np.linalg.norm(sim['cases1']-obs['cases1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "155dc9ad-f06a-4e14-829d-bdd187f59438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyabc\n",
    "from pyabc import ABCSMC, Distribution, RV, MultivariateNormalTransition, QuantileEpsilon\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "581cdd51-3283-4290-9998-845ab192643f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/python/sitecustomize.py:236: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  mod = _original_import(name, globals, locals, fromlist, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle \n",
    "\n",
    "from sbi.utils import BoxUniform\n",
    "from scipy.integrate import odeint\n",
    "from sbi.utils import MultipleIndependent\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.distributions import Uniform, Exponential, Cauchy\n",
    "\n",
    "_ = torch.manual_seed(0)\n",
    "_ = np.random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f975409c-7d1e-4c98-a457-81962a2ce45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from sbi.inference import NPE\n",
    "from sbi.neural_nets import posterior_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f4bb88-011b-49ff-a13c-fb6bdd8079f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "low  = torch.tensor([0.2, 0.1, 0.05])\n",
    "high = torch.tensor([1.5, 0.5, 0.4])\n",
    "\n",
    "prior = BoxUniform(low=low, high=high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "780edbd6-d840-4f65-b98f-d62096019d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMembedding(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=128, output_dim=30, num_layers=1,bidirectional=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, bidirectional=bidirectional, batch_first = True)\n",
    "        self.fc = nn.Linear(hidden_dim * (2 if bidirectional else 1), output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(-1)  \n",
    "        lstm_out, _ = self.lstm(x)  \n",
    "        last_hidden = lstm_out[:, -1, :]\n",
    "        last_hidden = self.dropout(last_hidden)\n",
    "        out = self.fc(last_hidden)   \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2600c1c5-04fb-480d-9b71-67959ac9b16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMembedding(\n",
       "  (lstm): LSTM(1, 128, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=30, bias=True)\n",
       "  (tanh): Tanh()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_net =LSTMembedding(input_dim=1, hidden_dim=128, output_dim=30).to(device)\n",
    "embedding_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "415a71cd-a3df-4530-8fe3-7bb8eab57f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = QuantileEpsilon(initial_epsilon='from_sample', alpha=0.2)\n",
    "transition = MultivariateNormalTransition(scaling=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fd942e-1a09-4702-885f-a3e928e20b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = Distribution(\n",
    "    beta=RV(\"uniform\", 0.2, 1.5),\n",
    "    kappa=RV(\"uniform\", 0.1, 0.5),\n",
    "    gamma=RV(\"uniform\", 0.05, 0.4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a441b140-3a10-4926-ba60-6dbf541a100a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6265e33-10b8-406f-ba7e-03b7a42db077",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"beta\", \"kappa\",\"gamma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009e154-c0e0-444e-9aac-faca33cd58e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ABC.Sampler INFO: Parallelize sampling on 128 processes.\n",
      "ABC.History INFO: Start <ABCSMC id=1, start_time=2026-01-31 17:24:31>\n",
      "ABC INFO: Calibration sample t = -1.\n",
      "ABC INFO: t: 0, eps: 7.05289597e+03.\n",
      "ABC INFO: Accepted: 100 / 895 = 1.1173e-01, ESS: 1.0000e+02.\n",
      "ABC INFO: Stop: Total simulations budget.\n",
      "ABC.History INFO: Done <ABCSMC id=1, duration=0:00:03.024111, end_time=2026-01-31 17:24:34>\n",
      "/tmp/ipykernel_2361139/2356125261.py:31: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  xs = torch.tensor(xs, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training neural network. Epochs trained: 80"
     ]
    }
   ],
   "source": [
    "pnpe_samples_1k=[]\n",
    "gene_num = 10\n",
    "\n",
    "for i, sim in enumerate(simulation_dataset):\n",
    "    obs_data = sim['poisson']\n",
    "    obs_dict={\"cases1\": obs_data[:,0]}\n",
    " \n",
    "    db_path = \"sqlite:///\" + tempfile.mkstemp(suffix=f\"abc_{i}.db\")[1]\n",
    "\n",
    "    abc = ABCSMC(model, prior, distance, population_size=100, transitions=transition, eps=eps)\n",
    "    abc.new(db_path, obs_dict)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = abc.run(max_total_nr_simulations=500)\n",
    "\n",
    "    df, weights = history.get_distribution()\n",
    "    df = df[param_names]\n",
    "    \n",
    "    kde_estimator = pyabc.transition.MultivariateNormalTransition()\n",
    "    kde_estimator.fit(df, weights)\n",
    "    abc_samples = kde_estimator.rvs(500)\n",
    "\n",
    "    x_obs = simulation_dataset[i]['poisson'][:,0]\n",
    "    \n",
    "    thetas = torch.tensor(np.array(abc_samples),dtype=torch.float32)\n",
    "\n",
    "    xs = []\n",
    "    for i, sample in abc_samples.iterrows():\n",
    "        x_sim = poisson_noise(simulate(sample.values, init_cond, duration))\n",
    "        xs.append(x_sim)\n",
    "    xs = torch.tensor(xs, dtype=torch.float32)\n",
    "\n",
    "    neural_posterior = posterior_nn(model='maf', embedding_net=embedding_net)\n",
    "    inference = NPE(density_estimator=neural_posterior,device=device)\n",
    "    \n",
    "    density_estimator=inference.append_simulations(thetas, xs).train(training_batch_size=64)\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    end_time = time.time()\n",
    "\n",
    "    samples = posterior.sample((10000,), x=x_obs)\n",
    "\n",
    "    print(f\"[{i}] Done in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    samples_df=pd.DataFrame(samples.cpu().numpy())\n",
    "    pnpe_samples_1k.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ebdeca-1086-46fc-985b-1d93175a2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./posterior/PNPE_1k.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pnpe_samples_1k, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3facd3-7c7b-46b0-b380-572a2ce83139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec84a86-650b-4ea2-b97e-327410af0c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c38cc-5dd6-4f4e-aee0-e3b7f2168396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bde7ceb-6d01-4c4d-a442-08b67499619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnpe_samples_10k=[]\n",
    "gene_num = 10\n",
    "\n",
    "for i, sim in enumerate(simulation_dataset):\n",
    "    obs_data = sim['poisson']\n",
    "    obs_dict={\"cases1\": obs_data[:,0]}\n",
    " \n",
    "    db_path = \"sqlite:///\" + tempfile.mkstemp(suffix=f\"abc_{i}.db\")[1]\n",
    "\n",
    "    abc = ABCSMC(model, prior, distance, population_size=100, transitions=transition, eps=eps)\n",
    "    abc.new(db_path, obs_dict)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = abc.run(max_total_nr_simulations=5000)\n",
    "\n",
    "    df, weights = history.get_distribution()\n",
    "    df = df[param_names]\n",
    "    \n",
    "    kde_estimator = pyabc.transition.MultivariateNormalTransition()\n",
    "    kde_estimator.fit(df, weights)\n",
    "    abc_samples = kde_estimator.rvs(5000)\n",
    "\n",
    "    x_obs = simulation_dataset[i]['poisson'][:,0]\n",
    "    \n",
    "    thetas = torch.tensor(np.array(abc_samples),dtype=torch.float32)\n",
    "\n",
    "    xs = []\n",
    "    for i, sample in abc_samples.iterrows():\n",
    "        x_sim = poisson_noise(simulate(sample.values, init_cond, duration))\n",
    "        xs.append(x_sim)\n",
    "    xs = torch.tensor(xs, dtype=torch.float32)\n",
    "\n",
    "    neural_posterior = posterior_nn(model='maf', embedding_net=embedding_net)\n",
    "    inference = NPE(density_estimator=neural_posterior,device=device)\n",
    "    \n",
    "    density_estimator=inference.append_simulations(thetas, xs).train(training_batch_size=128)\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    end_time = time.time()\n",
    "\n",
    "    samples = posterior.sample((10000,), x=x_obs)\n",
    "\n",
    "    print(f\"[{i}] Done in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    samples_df=pd.DataFrame(samples.cpu().numpy())\n",
    "    pnpe_samples_10k.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff39b7c-797a-4eba-9ce8-6c52a63755cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./posterior/PNPE_10k.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pnpe_samples_10k, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da36929-5564-42e1-8abf-fd8da8b075c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03edde-cacb-444f-b854-ad278ed1a471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725ec74-2047-44e8-9b96-9ddc88f27e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnpe_samples_100k=[]\n",
    "gene_num = 10\n",
    "\n",
    "for i, sim in enumerate(simulation_dataset):\n",
    "    obs_data = sim['poisson']\n",
    "    obs_dict={\"cases1\": obs_data[:,0]}\n",
    " \n",
    "    db_path = \"sqlite:///\" + tempfile.mkstemp(suffix=f\"abc_{i}.db\")[1]\n",
    "\n",
    "    abc = ABCSMC(model, prior, distance, population_size=1000, transitions=transition, eps=eps)\n",
    "    abc.new(db_path, obs_dict)\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = abc.run(max_total_nr_simulations=50000)\n",
    "\n",
    "    df, weights = history.get_distribution()\n",
    "    df = df[param_names]\n",
    "    \n",
    "    kde_estimator = pyabc.transition.MultivariateNormalTransition()\n",
    "    kde_estimator.fit(df, weights)\n",
    "    abc_samples = kde_estimator.rvs(50000)\n",
    "\n",
    "    x_obs = simulation_dataset[i]['poisson'][:,0]\n",
    "    \n",
    "    thetas = torch.tensor(np.array(abc_samples),dtype=torch.float32)\n",
    "\n",
    "    xs = []\n",
    "    for i, sample in abc_samples.iterrows():\n",
    "        x_sim = poisson_noise(simulate(sample.values, init_cond, duration))\n",
    "        xs.append(x_sim)\n",
    "    xs = torch.tensor(xs, dtype=torch.float32)\n",
    "\n",
    "    neural_posterior = posterior_nn(model='maf', embedding_net=embedding_net)\n",
    "    inference = NPE(density_estimator=neural_posterior,device=device)\n",
    "    \n",
    "    density_estimator=inference.append_simulations(thetas, xs).train(training_batch_size=256)\n",
    "    posterior = inference.build_posterior(density_estimator)\n",
    "    end_time = time.time()\n",
    "\n",
    "    samples = posterior.sample((10000,), x=x_obs)\n",
    "\n",
    "    print(f\"[{i}] Done in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    samples_df=pd.DataFrame(samples.cpu().numpy())\n",
    "    pnpe_samples_100k.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00d945c-d45f-44ec-988a-f1e5e021844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./posterior/PNPE_100k.pkl\", \"wb\") as file:\n",
    "    pickle.dump(pnpe_samples_100k, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "sbi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
